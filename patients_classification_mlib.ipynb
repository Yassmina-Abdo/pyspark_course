{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yassmina-Abdo/pyspark_course/blob/main/patients_classification_mlib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq4WFgMJz_6v"
      },
      "source": [
        "# Lab 2 PySpark:\n",
        "\n",
        "### Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHbD6L69z_63"
      },
      "source": [
        "#### But first, let's do some SQL :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puWN7EE1z_64"
      },
      "source": [
        "**First, install and import PySPark and SparkSession**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSVGKEGK4aQD",
        "outputId": "0f152085-ab98-49a5-b4d5-d64880a44b9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 44 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 13.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=02a9897dd0e8d42837f81528b14c4c106eac53e9444628942b4cee6b66030bcb\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tiq3KErWz_65"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, lit"
      ],
      "metadata": {
        "id": "UYagc_WbWe5J"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7XUKr7wz_67"
      },
      "source": [
        "**Now, download the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn4rXjWzz_67",
        "outputId": "1598d5cd-5600-4f8b-b6e6-492bb708d997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PB6wBDVTM_eocxOyi0lWlLBQOlH0rLe_\n",
            "To: /content/PatientInfo.csv\n",
            "\r  0% 0.00/489k [00:00<?, ?B/s]\r100% 489k/489k [00:00<00:00, 66.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1PB6wBDVTM_eocxOyi0lWlLBQOlH0rLe_ -O PatientInfo.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwJQOqxZz_69"
      },
      "source": [
        "**Create a SparkSession object and name the app \"Lab2\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "RHtAd4wAz_6-"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.master(\"local[1]\").appName('Lab2').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_B2cIgwz_6_"
      },
      "source": [
        "**1. Read the file PatientInfo.csv into a dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "NcNB5Xf1z_7A"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('/content/PatientInfo.csv', header = True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPIh8joLz_7A"
      },
      "source": [
        "**Show the first 5 lines of the dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpEv0cjpz_7B",
        "outputId": "b9d7585a-df32-4631-894c-6aa510463c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+-------------------+-------------------+-------------+--------+\n",
            "|patient_id|   sex|age|country|province|       city|      infection_case|infected_by|contact_number|symptom_onset_date|     confirmed_date|      released_date|deceased_date|   state|\n",
            "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+-------------------+-------------------+-------------+--------+\n",
            "|1000000001|  male|50s|  Korea|   Seoul| Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|2020-01-23 00:00:00|2020-02-05 00:00:00|         null|released|\n",
            "|1000000002|  male|30s|  Korea|   Seoul|Jungnang-gu|     overseas inflow|       null|            31|              null|2020-01-30 00:00:00|2020-03-02 00:00:00|         null|released|\n",
            "|1000000003|  male|50s|  Korea|   Seoul|  Jongno-gu|contact with patient| 2002000001|            17|              null|2020-01-30 00:00:00|2020-02-19 00:00:00|         null|released|\n",
            "|1000000004|  male|20s|  Korea|   Seoul|    Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|2020-01-30 00:00:00|2020-02-15 00:00:00|         null|released|\n",
            "|1000000005|female|20s|  Korea|   Seoul|Seongbuk-gu|contact with patient| 1000000002|             2|              null|2020-01-31 00:00:00|2020-02-24 00:00:00|         null|released|\n",
            "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+-------------------+-------------------+-------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igGqSilZz_7B"
      },
      "source": [
        "**Now do the same but using SQL select statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ5MD1unz_7B"
      },
      "source": [
        "1. Create a temporary view (table) called patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "0FjgJvCqz_7C"
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"patients\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BR2NlQjz_7C"
      },
      "source": [
        "2. Use SELECT statement to select all columns from the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma7DlsNxz_7D",
        "outputId": "4d23afa2-c85e-4a90-eb57-ea68298775aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+-------------------+-------------------+-------------+--------+\n",
            "|patient_id|   sex|age|country|province|        city|      infection_case|infected_by|contact_number|symptom_onset_date|     confirmed_date|      released_date|deceased_date|   state|\n",
            "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+-------------------+-------------------+-------------+--------+\n",
            "|1000000001|  male|50s|  Korea|   Seoul|  Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|2020-01-23 00:00:00|2020-02-05 00:00:00|         null|released|\n",
            "|1000000002|  male|30s|  Korea|   Seoul| Jungnang-gu|     overseas inflow|       null|            31|              null|2020-01-30 00:00:00|2020-03-02 00:00:00|         null|released|\n",
            "|1000000003|  male|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 2002000001|            17|              null|2020-01-30 00:00:00|2020-02-19 00:00:00|         null|released|\n",
            "|1000000004|  male|20s|  Korea|   Seoul|     Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|2020-01-30 00:00:00|2020-02-15 00:00:00|         null|released|\n",
            "|1000000005|female|20s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000002|             2|              null|2020-01-31 00:00:00|2020-02-24 00:00:00|         null|released|\n",
            "|1000000006|female|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|            43|              null|2020-01-31 00:00:00|2020-02-19 00:00:00|         null|released|\n",
            "|1000000007|  male|20s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|             0|              null|2020-01-31 00:00:00|2020-02-10 00:00:00|         null|released|\n",
            "|1000000008|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|2020-02-02 00:00:00|2020-02-24 00:00:00|         null|released|\n",
            "|1000000009|  male|30s|  Korea|   Seoul|   Songpa-gu|     overseas inflow|       null|            68|              null|2020-02-05 00:00:00|2020-02-21 00:00:00|         null|released|\n",
            "|1000000010|female|60s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000003|             6|              null|2020-02-05 00:00:00|2020-02-29 00:00:00|         null|released|\n",
            "|1000000011|female|50s|  China|   Seoul|Seodaemun-gu|     overseas inflow|       null|            23|              null|2020-02-06 00:00:00|2020-02-29 00:00:00|         null|released|\n",
            "|1000000012|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|2020-02-07 00:00:00|2020-02-27 00:00:00|         null|released|\n",
            "|1000000013|  male|80s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|           117|              null|2020-02-16 00:00:00|               null|         null|deceased|\n",
            "|1000000014|female|60s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000013|            27|        2020-02-06|2020-02-16 00:00:00|2020-03-12 00:00:00|         null|released|\n",
            "|1000000015|  male|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT|       null|             8|        2020-02-11|2020-02-19 00:00:00|               null|         null|released|\n",
            "|1000000016|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|          null|              null|2020-02-19 00:00:00|2020-03-11 00:00:00|         null|released|\n",
            "|1000000017|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|          null|              null|2020-02-20 00:00:00|2020-03-01 00:00:00|         null|released|\n",
            "|1000000018|  male|20s|  Korea|   Seoul|         etc|                 etc|       null|          null|              null|2020-02-20 00:00:00|               null|         null|released|\n",
            "|1000000019|female|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000021|          null|              null|2020-02-20 00:00:00|2020-03-08 00:00:00|         null|released|\n",
            "|1000000020|female|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT| 1000000015|          null|              null|2020-02-20 00:00:00|               null|         null|released|\n",
            "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+-------------------+-------------------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SELECT *  FROM patients\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh7lEuGjz_7D"
      },
      "source": [
        "3. Limit the output to only 5 rows *using SQL commands*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El5vy01mz_7D",
        "outputId": "a74e55ec-5347-407e-de44-dfc6c3dfaf3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+-------------------+-------------------+-------------+--------+\n",
            "|patient_id|   sex|age|country|province|       city|      infection_case|infected_by|contact_number|symptom_onset_date|     confirmed_date|      released_date|deceased_date|   state|\n",
            "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+-------------------+-------------------+-------------+--------+\n",
            "|1000000001|  male|50s|  Korea|   Seoul| Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|2020-01-23 00:00:00|2020-02-05 00:00:00|         null|released|\n",
            "|1000000002|  male|30s|  Korea|   Seoul|Jungnang-gu|     overseas inflow|       null|            31|              null|2020-01-30 00:00:00|2020-03-02 00:00:00|         null|released|\n",
            "|1000000003|  male|50s|  Korea|   Seoul|  Jongno-gu|contact with patient| 2002000001|            17|              null|2020-01-30 00:00:00|2020-02-19 00:00:00|         null|released|\n",
            "|1000000004|  male|20s|  Korea|   Seoul|    Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|2020-01-30 00:00:00|2020-02-15 00:00:00|         null|released|\n",
            "|1000000005|female|20s|  Korea|   Seoul|Seongbuk-gu|contact with patient| 1000000002|             2|              null|2020-01-31 00:00:00|2020-02-24 00:00:00|         null|released|\n",
            "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+-------------------+-------------------+-------------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SELECT *  FROM patients limit 5\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGfNJi-8z_7E"
      },
      "source": [
        "4. Select the count of males and females in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select SUM(case when sex = 'male' then 1 end) as Males_count\\\n",
        "                , SUM(case when sex = 'female' then 1 end) as Females_count\\\n",
        "                  FROM patients\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH_pYkRC8hza",
        "outputId": "5237fe26-226d-4853-ec67-4cb337c814ce"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+\n",
            "|Males_count|Females_count|\n",
            "+-----------+-------------+\n",
            "|       1825|         2218|\n",
            "+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO1XMoyPz_7E"
      },
      "source": [
        "5. Select the count of males and females *as percentage* (how many percent of the data are males and how many are females?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1w7CbLez_7F",
        "outputId": "3523e3b1-5cb2-492b-ce3e-2945e93eb0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------------+\n",
            "|      Males_count|     Females_count|\n",
            "+-----------------+------------------+\n",
            "|35.33397870280736|42.942884801548885|\n",
            "+-----------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select 100 * SUM(case when sex = 'male' then 1 end)/count(*) as Males_count\\\n",
        "                , 100 * SUM(case when sex = 'female' then 1 end)/count(*) as Females_count\\\n",
        "                  FROM patients\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX9ruFHjz_7F"
      },
      "source": [
        "6. How many people did survive, and how many didn't?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW9KJ14Zz_7F",
        "outputId": "233b58a1-40da-484c-ca40-27365799d1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|survive|not_survive|\n",
            "+-------+-----------+\n",
            "|     78|       5087|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select SUM(case when state = 'deceased' then  1 end) as survive\\\n",
        "                , SUM(case when state != 'deceased' then 1 end) as not_survive\\\n",
        "                  FROM patients\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0wL-Hf9z_7F"
      },
      "source": [
        "Now, let's perform some preprocessing using SQL:\n",
        "\n",
        "1. Convert *age* column to double after removing the 's' at the end -- *hint: check SUBSTRING method*\n",
        "2. Select only the following columns: `['sex', 'age', 'province', 'state']`\n",
        "3. Store the result of the query in a new dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. \n",
        "spark.sql(\"select double(SUBSTRING(age,1,Length(age)-1)) AS Age from patients \").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vftg5yX3Bsrs",
        "outputId": "9c3d7084-1513-49c8-bda8-423c2b8a577d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "| Age|\n",
            "+----+\n",
            "|50.0|\n",
            "|30.0|\n",
            "|50.0|\n",
            "|20.0|\n",
            "|20.0|\n",
            "|50.0|\n",
            "|20.0|\n",
            "|20.0|\n",
            "|30.0|\n",
            "|60.0|\n",
            "|50.0|\n",
            "|20.0|\n",
            "|80.0|\n",
            "|60.0|\n",
            "|70.0|\n",
            "|70.0|\n",
            "|70.0|\n",
            "|20.0|\n",
            "|70.0|\n",
            "|70.0|\n",
            "+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "dW3PPynWz_7F"
      },
      "outputs": [],
      "source": [
        "#2., 3.\n",
        "selected_df= spark.sql(\"select sex,double(SUBSTRING(age,1,Length(age)-1)) AS Age,province,state from patients \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gehQTBJfz_7G"
      },
      "source": [
        "Now view the new dataframe to make sure everything is alright"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-je80HKz_7G",
        "outputId": "2498b29b-16ed-48c8-d094-d457e01d3a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+--------+--------+\n",
            "|   sex| Age|province|   state|\n",
            "+------+----+--------+--------+\n",
            "|  male|50.0|   Seoul|released|\n",
            "|  male|30.0|   Seoul|released|\n",
            "|  male|50.0|   Seoul|released|\n",
            "|  male|20.0|   Seoul|released|\n",
            "|female|20.0|   Seoul|released|\n",
            "|female|50.0|   Seoul|released|\n",
            "|  male|20.0|   Seoul|released|\n",
            "|  male|20.0|   Seoul|released|\n",
            "|  male|30.0|   Seoul|released|\n",
            "|female|60.0|   Seoul|released|\n",
            "|female|50.0|   Seoul|released|\n",
            "|  male|20.0|   Seoul|released|\n",
            "|  male|80.0|   Seoul|deceased|\n",
            "|female|60.0|   Seoul|released|\n",
            "|  male|70.0|   Seoul|released|\n",
            "|  male|70.0|   Seoul|released|\n",
            "|  male|70.0|   Seoul|released|\n",
            "|  male|20.0|   Seoul|released|\n",
            "|female|70.0|   Seoul|released|\n",
            "|female|70.0|   Seoul|released|\n",
            "+------+----+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "selected_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z8fT7jsz_7G"
      },
      "source": [
        "**Now, let's get back to spark operations**\n",
        "\n",
        "Please copy the following operations from your solution in Lab 1\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQCKU_ZZz_7G"
      },
      "source": [
        "Add a **is_dead** column if patient state is not released then it should yield true, else then False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb2FLT7mz_7H",
        "outputId": "6cd3127a-28cd-4804-bffc-81bfb0934d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+--------+--------+-------+\n",
            "|   sex| Age|province|   state|is_dead|\n",
            "+------+----+--------+--------+-------+\n",
            "|  male|50.0|   Seoul|released|      0|\n",
            "|  male|30.0|   Seoul|released|      0|\n",
            "|  male|50.0|   Seoul|released|      0|\n",
            "|  male|20.0|   Seoul|released|      0|\n",
            "|female|20.0|   Seoul|released|      0|\n",
            "|female|50.0|   Seoul|released|      0|\n",
            "|  male|20.0|   Seoul|released|      0|\n",
            "|  male|20.0|   Seoul|released|      0|\n",
            "|  male|30.0|   Seoul|released|      0|\n",
            "|female|60.0|   Seoul|released|      0|\n",
            "|female|50.0|   Seoul|released|      0|\n",
            "|  male|20.0|   Seoul|released|      0|\n",
            "|  male|80.0|   Seoul|deceased|      1|\n",
            "|female|60.0|   Seoul|released|      0|\n",
            "|  male|70.0|   Seoul|released|      0|\n",
            "|  male|70.0|   Seoul|released|      0|\n",
            "|  male|70.0|   Seoul|released|      0|\n",
            "|  male|20.0|   Seoul|released|      0|\n",
            "|female|70.0|   Seoul|released|      0|\n",
            "|female|70.0|   Seoul|released|      0|\n",
            "+------+----+--------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "selected_df = selected_df.withColumn(\"is_dead\",\\\n",
        "                  when((selected_df.state == 'deceased'), lit(1))\\\n",
        "                 .otherwise(lit(0)))\n",
        "selected_df.show()                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C13MKSIBz_7H"
      },
      "source": [
        "**Please split the data into train and test dataframes**\n",
        "\n",
        "*Ratio: 80:20 - Seed=42*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "V7oDwXXfz_7H"
      },
      "outputs": [],
      "source": [
        "trainDF, testDF = selected_df.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "892nejAgz_7I"
      },
      "source": [
        "**Now, let's import RandomForestClassifier and start our ML pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "kZXkj-r9z_7I"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4i_JX4Hz_7I"
      },
      "source": [
        "**Create a pipeline that contains the following stages:**\n",
        "\n",
        "- Imputer: impute the null values in `age` column to the mean value\n",
        "- StringIndexer: convert `sex` to `is_male` and `province` to `province_index` as numerical values\n",
        "- OneHotEncoder: perform one hot encoding on both `is_male` and -province_index`\n",
        "- VectorAssembler: assemble feature vector from the following columns: `'age', 'is_male', 'province_index'`\n",
        "- RandomForestClassifier: final estimator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.\n",
        "imputer= Imputer(inputCol='Age', outputCol= 'Age').setStrategy(\"mean\")\n",
        "#2. \n",
        "stringindexer= StringIndexer(inputCols=[\"sex\",\"province\"], outputCols=[\"is_male\",\"province_index\"],handleInvalid = \"skip\")\n",
        "#3.\n",
        "onehotEncoder= OneHotEncoder(inputCols=[\"is_male\",\"province_index\"], outputCols=[\"Is_male\",\"Province_Index\"])\n",
        "#4.\n",
        "vectorAssembler= VectorAssembler(inputCols = [\"Age\", \"Is_male\", \"Province_Index\"], outputCol = \"features\",handleInvalid = \"skip\")\n",
        "#5.\n",
        "model= RandomForestClassifier(featuresCol='features',labelCol='is_dead')"
      ],
      "metadata": {
        "id": "gJ3jMIXtMLDm"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "GIchzy38z_7J"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[imputer, stringindexer, onehotEncoder, vectorAssembler,model])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHjYnDb_z_7J"
      },
      "source": [
        "Fit the pipeline to the train dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "088-Y-vOz_7J"
      },
      "outputs": [],
      "source": [
        "pl_Model=pipeline.fit(trainDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWUo0_f5z_7K"
      },
      "source": [
        "Now transform the test DF to get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "2cYq6693z_7K"
      },
      "outputs": [],
      "source": [
        "predDF = pl_Model.transform(testDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEKMCrRsz_7K"
      },
      "source": [
        "Show the final predictions DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btOKPJGrz_7K",
        "outputId": "a01d8092-2bd2-4bd9-9f64-15f8091a7dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------+-------+----------+\n",
            "|features                               |is_dead|prediction|\n",
            "+---------------------------------------+-------+----------+\n",
            "|(18,[0,1,3],[40.0494233937397,1.0,1.0])|0      |0.0       |\n",
            "|(18,[0,1,3],[40.0494233937397,1.0,1.0])|0      |0.0       |\n",
            "|(18,[0,1,5],[40.0494233937397,1.0,1.0])|0      |0.0       |\n",
            "|(18,[0,1,5],[40.0494233937397,1.0,1.0])|0      |0.0       |\n",
            "|(18,[0,1,5],[40.0494233937397,1.0,1.0])|0      |0.0       |\n",
            "+---------------------------------------+-------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predDF.select('features','is_dead','prediction').show(5,truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4toiOr_z_7K"
      },
      "source": [
        "**Model Evaluation**\n",
        "\n",
        "Now let's evaluate our model! Let's get the accuracy of our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "G3-luVJzz_7K"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy**"
      ],
      "metadata": {
        "id": "Ak_SggJKqk_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval= MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"is_dead\")\n",
        "acc_res  = eval.evaluate(predDF, {eval.metricName:\"accuracy\"})\n",
        "print(\"Accuracy = %0.2f\" % acc_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy7PazBmqHHw",
        "outputId": "a72d07a4-902a-4061-a140-5f61b3272237"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC**"
      ],
      "metadata": {
        "id": "Kr-yVed5qojV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "YrqEvbFbz_7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fef7f54-879c-49fa-98f4-9594a89f972b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roc=  0.5\n"
          ]
        }
      ],
      "source": [
        "eval= BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='is_dead',metricName='areaUnderROC')\n",
        "print(f'Roc= ',eval.evaluate(predDF))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vOLOJklz_7L"
      },
      "source": [
        "Excellent! Now let's generate the confusion matrix of our predictions\n",
        "\n",
        "*Hint: we can use `scikit-learn`'s `classification_report`. You will need to transform the predictions into pandas DF first*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "Zj4mKq70z_7L"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predDF_pd = predDF.toPandas()\n",
        "print(classification_report(predDF_pd['is_dead'], predDF_pd['prediction']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiY9mlBXonD6",
        "outputId": "de75ceb8-d048-4649-934e-015d6fe7b886"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       790\n",
            "           1       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.98       810\n",
            "   macro avg       0.49      0.50      0.49       810\n",
            "weighted avg       0.95      0.98      0.96       810\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFA2qXDWz_7L"
      },
      "source": [
        "## Great Job!\n",
        "\n",
        "**If you followed the instructions correctly, you should get a total accuracy of 89%, and F1 scores of 92% and 85%**\n",
        "\n",
        "**Do you think you can improve this accuracy? Let's see what you can do :)**\n",
        "\n",
        "___\n",
        "If you have any questions you can reach out to me:\n",
        "\n",
        "### Omar Hammad\n",
        "#### Software Engineer\n",
        "##### Email: ommar365@gmail.com\n",
        "##### Phone: 01144070145\n",
        "##### Linkedin: https://www.linkedin.com/in/omar-a-hammad"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "dd1a844898bebfcc6c6c504d1dc786ee6fa9d0c6b1f1b5f42f0cc60440be92ab"
      }
    },
    "colab": {
      "name": "Yassmina_Abdo_Practical_Session_2_v2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}